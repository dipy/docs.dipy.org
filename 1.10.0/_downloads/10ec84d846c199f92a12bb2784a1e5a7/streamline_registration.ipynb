{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Applying image-based deformations to streamlines\n\nThis example shows how to register streamlines into a template space by\napplying non-rigid deformations.\n\nAt times we will be interested in bringing a set of streamlines into some\ncommon, reference space to compute statistics out of the registered\nstreamlines. For a discussion on the effects of spatial normalization\napproaches on tractography the work by :footcite:t:`Greene2018` can be read.\n\nFor brevity, we will include in this example only streamlines going through\nthe corpus callosum connecting left to right superior frontal cortex. The\nprocess of tracking and finding these streamlines is fully demonstrated in\nthe `sphx_glr_examples_built_streamline_analysis_streamline_tools.py`\nexample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from os.path import join as pjoin\n\nimport numpy as np\n\nfrom dipy.align import affine_registration, syn_registration\nfrom dipy.align.reslice import reslice\nfrom dipy.core.gradients import gradient_table\nfrom dipy.data import fetch_stanford_tracks, get_fnames\nfrom dipy.data.fetcher import fetch_mni_template, read_mni_template\nfrom dipy.io.gradients import read_bvals_bvecs\nfrom dipy.io.image import load_nifti\nfrom dipy.io.stateful_tractogram import Space, StatefulTractogram\nfrom dipy.io.streamline import load_tractogram, save_tractogram\nfrom dipy.segment.mask import median_otsu\nfrom dipy.tracking.streamline import transform_streamlines\nfrom dipy.viz import has_fury, horizon, regtools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to get the deformation field, we will first use two b0 volumes. Both\nmoving and static images are assumed to be in RAS. The first one will be the\nb0 from the Stanford HARDI dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames(name=\"stanford_hardi\")\n\ndwi_data, dwi_affine, dwi_img = load_nifti(hardi_fname, return_img=True)\ndwi_vox_size = dwi_img.header.get_zooms()[0]\ndwi_bvals, dwi_bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\ngtab = gradient_table(dwi_bvals, bvecs=dwi_bvecs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second one will be the T2-contrast MNI template image. The resolution of\nthe MNI template is 1x1x1 mm. However, the resolution of the Stanford HARDI\ndiffusion data is 2x2x2 mm. Thus, we'll need to reslice to 2x2x2 mm\nisotropic voxel resolution to match the HARDI data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fetch_mni_template()\nimg_t2_mni = read_mni_template(version=\"a\", contrast=\"T2\")\nt2_mni_data, t2_mni_affine = img_t2_mni.get_fdata(), img_t2_mni.affine\nt2_mni_voxel_size = img_t2_mni.header.get_zooms()[:3]\nnew_voxel_size = (2.0, 2.0, 2.0)\n\nt2_resliced_data, t2_resliced_affine = reslice(\n    t2_mni_data, t2_mni_affine, t2_mni_voxel_size, new_voxel_size\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We remove the skull of the dwi_data. For this, we need to get the b0 volumes\nindexes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "b0_idx_stanford = np.where(gtab.b0s_mask)[0].tolist()\ndwi_data_noskull, _ = median_otsu(dwi_data, vol_idx=b0_idx_stanford, numpass=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We filter the diffusion data from the Stanford HARDI dataset to find all the\nb0 images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "b0_data_stanford = dwi_data_noskull[..., gtab.b0s_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And go on to compute the Stanford HARDI dataset mean b0 image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_b0_masked_stanford = np.mean(b0_data_stanford, axis=3, dtype=dwi_data.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will register the mean b0 to the MNI T2 image template non-rigidly to\nobtain the deformation field that will be applied to the streamlines. This is\njust one of the strategies that can be used to obtain an appropriate\ndeformation field. Other strategies include computing an FA template map as\nthe static image, and registering the FA map of the moving image to it. This\nmay may eventually lead to results with improved accuracy, since a\nT2-contrast template image as the target for normalization does not provide\noptimal tissue contrast for maximal SyN performance.\n\nWe will first perform an affine registration to roughly align the two\nvolumes:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = [\n    \"center_of_mass\",\n    \"translation\",\n    \"rigid\",\n    \"rigid_isoscaling\",\n    \"rigid_scaling\",\n    \"affine\",\n]\nlevel_iters = [10000, 1000, 100]\nsigmas = [3.0, 1.0, 0.0]\nfactors = [4, 2, 1]\n\n\nwarped_b0, warped_b0_affine = affine_registration(\n    mean_b0_masked_stanford,\n    t2_resliced_data,\n    moving_affine=dwi_affine,\n    static_affine=t2_resliced_affine,\n    pipeline=pipeline,\n    level_iters=level_iters,\n    sigmas=sigmas,\n    factors=factors,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now perform the non-rigid deformation using the Symmetric Diffeomorphic\nRegistration (SyN) Algorithm proposed by :footcite:t:`Avants2008` (also\nimplemented in the ANTs software :footcite:p:`Avants2009`):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "level_iters = [10, 10, 5]\n\nfinal_warped_b0, mapping = syn_registration(\n    mean_b0_masked_stanford,\n    t2_resliced_data,\n    moving_affine=dwi_affine,\n    static_affine=t2_resliced_affine,\n    prealign=warped_b0_affine,\n    level_iters=level_iters,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We show the registration result with:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regtools.overlay_slices(\n    t2_resliced_data,\n    final_warped_b0,\n    slice_index=None,\n    slice_type=0,\n    ltitle=\"Static\",\n    rtitle=\"Moving\",\n    fname=\"transformed_sagittal.png\",\n)\nregtools.overlay_slices(\n    t2_resliced_data,\n    final_warped_b0,\n    slice_index=None,\n    slice_type=1,\n    ltitle=\"Static\",\n    rtitle=\"Moving\",\n    fname=\"transformed_coronal.png\",\n)\nregtools.overlay_slices(\n    t2_resliced_data,\n    final_warped_b0,\n    slice_index=None,\n    slice_type=2,\n    ltitle=\"Static\",\n    rtitle=\"Moving\",\n    fname=\"transformed_axial.png\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n\nDeformable registration result.\n\n\nLet's now fetch a set of streamlines from the Stanford HARDI dataset.\nThose streamlines were generated during the\n`sphx_glr_examples_built_streamline_analysis_streamline_tools.py`\nexample.\n\nWe read the streamlines from file in voxel space:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "streamlines_files = fetch_stanford_tracks()\nlr_superiorfrontal_path = pjoin(streamlines_files[1], \"hardi-lr-superiorfrontal.trk\")\n\nsft = load_tractogram(lr_superiorfrontal_path, \"same\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The affine registration already gives a pretty good result. We could use its\nmapping to transform the streamlines to the anatomical space (MNI T2 image).\nFor that, we use `transform_streamlines` and `warped_b0_affine`. Do not\nforget that `warp_b0_affine` is the affine transformation from the mean b0\nimage to the T2 template image. Thus, you typically need to apply the inverse\ntransformation of the affine transformation matrix that was used to register\nthe two images. This is because the transformation matrix describes how\npoints in one image (mean_b0) are mapped to points in the other image\n(mni T2), and to move points from the warped_b0 space to the t2 space,\nyou need to \"undo\" this transformation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mni_t2_streamlines_using_affine_reg = transform_streamlines(\n    sft.streamlines, np.linalg.inv(warped_b0_affine)\n)\n\nsft_in_t2_using_aff_reg = StatefulTractogram(\n    mni_t2_streamlines_using_affine_reg, img_t2_mni, Space.RASMM\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's visualize the streamlines in the MNI T2 space. Switch the interactive\nvariable to True if you want to explore the visualization in an interactive\nwindow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interactive = False\n\nif has_fury:\n    horizon(\n        tractograms=[sft_in_t2_using_aff_reg],\n        images=[(t2_mni_data, t2_mni_affine)],\n        interactive=interactive,\n        world_coords=True,\n        out_png=\"streamlines_DSN_MNI_aff_reg.png\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get better result, we use the mapping obtain by Symmetric Diffeomorphic\nRegistration (SyN). Then, we can visualize the corpus callosum bundles\nthat have been deformed to adapt to the MNI template space.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mni_t2_streamlines_using_syn = mapping.transform_points_inverse(sft.streamlines)\n\nsft_in_t2_using_syn = StatefulTractogram(\n    mni_t2_streamlines_using_syn, img_t2_mni, Space.RASMM\n)\n\nif has_fury:\n    horizon(\n        tractograms=[sft_in_t2_using_syn],\n        images=[(t2_mni_data, t2_mni_affine)],\n        interactive=interactive,\n        world_coords=True,\n        out_png=\"streamlines_DSN_MNI_syn.png\",\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we save the two registered streamlines:\n\n- `mni-lr-sft_in_t2_using_aff_reg.trk` is the streamlines registered using\n  the affine registration.\n- `sft_in_t2_using_syn` is the streamlines registered using the\n  SyN registration and prealigned with the affine registration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "save_tractogram(\n    sft_in_t2_using_aff_reg,\n    \"mni-lr-superiorfrontal_aff_reg.trk\",\n    bbox_valid_check=False,\n)\n\nsave_tractogram(\n    sft_in_t2_using_syn, \"mni-lr-superiorfrontal_syn.trk\", bbox_valid_check=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. footbibliography::\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. include:: ../../links_names.inc\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}