{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Symmetric Diffeomorphic Registration in 3D\nThis example explains how to register 3D volumes using the Symmetric\nNormalization (SyN) algorithm proposed by :footcite:t:`Avants2008` (also\nimplemented in the ANTs software :footcite:p:`Avants2009`)\n\nWe will register two 3D volumes from the same modality using SyN with the Cross\n-Correlation (CC) metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom dipy.align import read_mapping, write_mapping\nfrom dipy.align.imaffine import AffineMap\nfrom dipy.align.imwarp import SymmetricDiffeomorphicRegistration\nfrom dipy.align.metrics import CCMetric\nfrom dipy.data import get_fnames\nfrom dipy.io.image import load_nifti\nfrom dipy.segment.mask import median_otsu\nfrom dipy.viz import regtools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's fetch two b0 volumes, the first one will be the b0 from the Stanford\nHARDI dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames(name=\"stanford_hardi\")\n\nstanford_b0, stanford_b0_affine = load_nifti(hardi_fname)\nstanford_b0 = np.squeeze(stanford_b0)[..., 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second one will be the same b0 we used for the 2D registration tutorial\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "t1_fname, b0_fname = get_fnames(name=\"syn_data\")\nsyn_b0, syn_b0_affine = load_nifti(b0_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first remove the skull from the b0's\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stanford_b0_masked, stanford_b0_mask = median_otsu(\n    stanford_b0, median_radius=4, numpass=4\n)\nsyn_b0_masked, syn_b0_mask = median_otsu(syn_b0, median_radius=4, numpass=4)\n\nstatic = stanford_b0_masked\nstatic_affine = stanford_b0_affine\nmoving = syn_b0_masked\nmoving_affine = syn_b0_affine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we have already done a linear registration to roughly align the two\nimages\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pre_align = np.array(\n    [\n        [1.02783543e00, -4.83019053e-02, -6.07735639e-02, -2.57654118e00],\n        [4.34051706e-03, 9.41918267e-01, -2.66525861e-01, 3.23579799e01],\n        [5.34288908e-02, 2.90262026e-01, 9.80820307e-01, -1.46216651e01],\n        [0.00000000e00, 0.00000000e00, 0.00000000e00, 1.00000000e00],\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we did in the 2D example, we would like to visualize (some slices of) the\ntwo volumes by overlapping them over two channels of a color image. To do\nthat we need them to be sampled on the same grid, so let's first re-sample\nthe moving image on the static grid. We create an AffineMap to transform the\nmoving image towards the static image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "affine_map = AffineMap(\n    pre_align,\n    domain_grid_shape=static.shape,\n    domain_grid2world=static_affine,\n    codomain_grid_shape=moving.shape,\n    codomain_grid2world=moving_affine,\n)\n\nresampled = affine_map.transform(moving)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot the overlapped middle slices of the volumes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regtools.overlay_slices(\n    static,\n    resampled,\n    slice_index=None,\n    slice_type=1,\n    ltitle=\"Static\",\n    rtitle=\"Moving\",\n    fname=\"input_3d.png\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n\nStatic image in red on top of the pre-aligned moving image (in green).\n\n\n\nWe want to find an invertible map that transforms the moving image into the\nstatic image. We will use the Cross-Correlation metric\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metric = CCMetric(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define an instance of the registration class. The SyN algorithm uses\na multi-resolution approach by building a Gaussian Pyramid. We instruct the\nregistration object to perform at most $[n_0, n_1, ..., n_k]$ iterations at\neach level of the pyramid. The 0-th level corresponds to the finest\nresolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "level_iters = [10, 10, 5]\nsdr = SymmetricDiffeomorphicRegistration(metric, level_iters=level_iters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the optimization, which returns a DiffeomorphicMap object,\nthat can be used to register images back and forth between the static and\nmoving domains. We provide the pre-aligning matrix that brings the moving\nimage closer to the static image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mapping = sdr.optimize(\n    static,\n    moving,\n    static_grid2world=static_affine,\n    moving_grid2world=moving_affine,\n    prealign=pre_align,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's warp the moving image and see if it gets similar to the static\nimage\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "warped_moving = mapping.transform(moving)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the overlapped middle slices\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "regtools.overlay_slices(\n    static,\n    warped_moving,\n    slice_index=None,\n    slice_type=1,\n    ltitle=\"Static\",\n    rtitle=\"Warped moving\",\n    fname=\"warped_moving.png\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n\nMoving image transformed under the (direct) transformation in green on top\nof the static image (in red).\n\n\n\nAnd we can also apply the inverse mapping to verify that the warped static\nimage is similar to the moving image\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "warped_static = mapping.transform_inverse(static)\nregtools.overlay_slices(\n    warped_static,\n    moving,\n    slice_index=None,\n    slice_type=1,\n    ltitle=\"Warped static\",\n    rtitle=\"Moving\",\n    fname=\"warped_static.png\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. rst-class:: centered small fst-italic fw-semibold\n\nStatic image transformed under the (inverse) transformation in red on top of\nthe moving image (in green). Note that the moving image has a lower\nresolution.\n\n\nIf you wish, you can also save the transformation to a file, so that it can\nbe applied to other images in the future. This can be done with the\n`write_mapping` function. The data in the file will be organized with shape\n(X, Y, Z, 3, 2), such that the forward mapping in each voxel is in\ndata[i, j, k, :, 0] and the backward mapping in each voxel is in\ndata[i, j, k, :, 1]\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "write_mapping(mapping, \"mapping.nii.gz\")\n# To read the mapping back, use the `read_mapping` function\nsaved_mapping = read_mapping(\"mapping.nii.gz\", hardi_fname, b0_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. footbibliography::\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. include:: ../../links_names.inc\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}